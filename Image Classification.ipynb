{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['femaleeyes', 'maleeyes']\n",
    "\n",
    "def check_dimensions():\n",
    "    \"\"\"\n",
    "    Given folder path, return the largest and smallest dimensions.\n",
    "    \"\"\"\n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "    x_min = 200\n",
    "    y_min = 200\n",
    "    for cat in CATEGORIES:\n",
    "        path_list = glob.glob(os.path.join('dataset', cat, '*.jpg'))\n",
    "        for image_path in path_list:\n",
    "            image = np.array(Image.open(image_path))\n",
    "            if image.shape[0] > x_max:\n",
    "                x_max = image.shape[0]\n",
    "            if image.shape[1] > y_max:\n",
    "                y_max = image.shape[0]\n",
    "            if image.shape[0] < x_min:\n",
    "                x_min = image.shape[0]\n",
    "            if image.shape[1] < y_min:\n",
    "                y_min = image.shape[0]\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                # Print any pair of dimensions in case of non-square.\n",
    "                print(f\"Irregular: {image.shape[0]}, {image.shape[1]}\")\n",
    "    return x_max, y_max, x_min, y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 117, 41, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_DIM = 50\n",
    "INPUT_SHAPE = (RESIZE_DIM, RESIZE_DIM, 3)\n",
    "BS = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entry(image_path, category):\n",
    "    \"\"\"\n",
    "    Given file path and of an image, return a pandas series of a numpy array of\n",
    "    pixel data (width, height, channels), along with category in integer indices\n",
    "    if category (string) is given.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((RESIZE_DIM, RESIZE_DIM))\n",
    "    return np.array(image) / 255.0, CATEGORIES.index(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images():\n",
    "    \"\"\"\n",
    "    Given folder path, return a pandas dataframe of image data.\n",
    "    \"\"\"\n",
    "    image_X = []\n",
    "    image_y = []\n",
    "    for cat in CATEGORIES:\n",
    "        path_list = glob.glob(os.path.join('dataset', cat, '*.jpg'))\n",
    "        for image_path in path_list:\n",
    "            image_array, category_int = generate_entry(image_path, cat)\n",
    "            image_X.append(image_array)\n",
    "            image_y.append(category_int)\n",
    "    X = np.stack(image_X)\n",
    "    y = np.array(image_y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_images(X, y):\n",
    "    \"\"\"\n",
    "    Given image data X and category y, shuffle them in the same order.\n",
    "    \"\"\"\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(X)\n",
    "    # Use the same RNG state so that X and y are shuffled in the same way.\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Create the neural network model.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
    "    # First convolutional layer\n",
    "    x = tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    # Second convolutional layer\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    # Third convolutional layer\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    # First fully connected layer\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    # Final fully connected layer\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x, name=\"image_classification\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle_images(*get_images())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "289/289 [==============================] - 10s 34ms/step - loss: 0.4498 - accuracy: 0.8092\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 9s 31ms/step - loss: 0.3008 - accuracy: 0.8772\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 9s 30ms/step - loss: 0.2830 - accuracy: 0.8819\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 9s 30ms/step - loss: 0.2538 - accuracy: 0.8960\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 9s 33ms/step - loss: 0.2260 - accuracy: 0.9120\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.2243 - accuracy: 0.9065\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 9s 32ms/step - loss: 0.2186 - accuracy: 0.9119\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 9s 32ms/step - loss: 0.2079 - accuracy: 0.9145\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 10s 36ms/step - loss: 0.2284 - accuracy: 0.9093\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 9s 31ms/step - loss: 0.1927 - accuracy: 0.9246\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction from testing dataset\n",
    "\n",
    "y_pred = model.predict(X_test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 982,   44],\n",
       "       [ 172, 1107]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion amtrix from testing dataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
