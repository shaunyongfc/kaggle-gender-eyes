{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['femaleeyes', 'maleeyes']\n",
    "\n",
    "def check_dimensions():\n",
    "    \"\"\"\n",
    "    Given folder path, return the largest and smallest dimensions.\n",
    "    \"\"\"\n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "    x_min = 200\n",
    "    y_min = 200\n",
    "    for cat in CATEGORIES:\n",
    "        path_list = glob.glob(os.path.join('dataset', cat, '*.jpg'))\n",
    "        for image_path in path_list:\n",
    "            image = np.array(Image.open(image_path))\n",
    "            if image.shape[0] > x_max:\n",
    "                x_max = image.shape[0]\n",
    "            if image.shape[1] > y_max:\n",
    "                y_max = image.shape[0]\n",
    "            if image.shape[0] < x_min:\n",
    "                x_min = image.shape[0]\n",
    "            if image.shape[1] < y_min:\n",
    "                y_min = image.shape[0]\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                # Print any pair of dimensions in case of non-square.\n",
    "                print(f\"Irregular: {image.shape[0]}, {image.shape[1]}\")\n",
    "    return x_max, y_max, x_min, y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 117, 41, 41)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_DIM = 54\n",
    "INPUT_SHAPE = (RESIZE_DIM, RESIZE_DIM, 3)\n",
    "BS = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entry(image_path, category):\n",
    "    \"\"\"\n",
    "    Given file path and of an image, return a pandas series of a numpy array of\n",
    "    pixel data (width, height, channels), along with category in integer indices\n",
    "    if category (string) is given.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((RESIZE_DIM, RESIZE_DIM))\n",
    "    return np.array(image) / 255.0, CATEGORIES.index(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images():\n",
    "    \"\"\"\n",
    "    Given folder path, return a pandas dataframe of image data.\n",
    "    \"\"\"\n",
    "    image_X = []\n",
    "    image_y = []\n",
    "    for cat in CATEGORIES:\n",
    "        path_list = glob.glob(os.path.join('dataset', cat, '*.jpg'))\n",
    "        for image_path in path_list:\n",
    "            image_array, category_int = generate_entry(image_path, cat)\n",
    "            image_X.append(image_array)\n",
    "            image_y.append(category_int)\n",
    "    X = np.stack(image_X)\n",
    "    y = np.array(image_y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_images(X, y):\n",
    "    \"\"\"\n",
    "    Given image data X and category y, shuffle them in the same order.\n",
    "    \"\"\"\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(X)\n",
    "    # Use the same RNG state so that X and y are shuffled in the same way.\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Create the neural network model.\n",
    "    \"\"\"\n",
    "    # Input dimensions 54 x 54 x 3\n",
    "    inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
    "    # First convolutional layer, 18 x 18 x 16\n",
    "    x = tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    # Second convolutional layer, 6 x 6 x 32\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    # First fully connected layer, 20\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(20, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    # Final fully connected layer\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x, name=\"image_classification\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle_images(*get_images())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "289/289 [==============================] - 10s 32ms/step - loss: 0.4119 - accuracy: 0.8158\n",
      "Epoch 2/20\n",
      "289/289 [==============================] - 9s 32ms/step - loss: 0.2928 - accuracy: 0.8784\n",
      "Epoch 3/20\n",
      "289/289 [==============================] - 9s 32ms/step - loss: 0.2757 - accuracy: 0.8862\n",
      "Epoch 4/20\n",
      "289/289 [==============================] - 9s 32ms/step - loss: 0.2589 - accuracy: 0.8925\n",
      "Epoch 5/20\n",
      "289/289 [==============================] - 10s 34ms/step - loss: 0.2189 - accuracy: 0.9138\n",
      "Epoch 6/20\n",
      "289/289 [==============================] - 9s 32ms/step - loss: 0.2123 - accuracy: 0.9132\n",
      "Epoch 7/20\n",
      "289/289 [==============================] - 10s 34ms/step - loss: 0.1938 - accuracy: 0.9257\n",
      "Epoch 8/20\n",
      "289/289 [==============================] - 10s 33ms/step - loss: 0.1895 - accuracy: 0.9239\n",
      "Epoch 9/20\n",
      "289/289 [==============================] - 9s 33ms/step - loss: 0.1818 - accuracy: 0.9255\n",
      "Epoch 10/20\n",
      "289/289 [==============================] - 9s 32ms/step - loss: 0.1745 - accuracy: 0.9302\n",
      "Epoch 11/20\n",
      "289/289 [==============================] - 9s 33ms/step - loss: 0.1713 - accuracy: 0.9319\n",
      "Epoch 12/20\n",
      "289/289 [==============================] - 10s 33ms/step - loss: 0.1534 - accuracy: 0.9405\n",
      "Epoch 13/20\n",
      "289/289 [==============================] - 10s 34ms/step - loss: 0.1496 - accuracy: 0.9418\n",
      "Epoch 14/20\n",
      "289/289 [==============================] - 10s 34ms/step - loss: 0.1448 - accuracy: 0.9413\n",
      "Epoch 15/20\n",
      "289/289 [==============================] - 11s 38ms/step - loss: 0.1404 - accuracy: 0.9452\n",
      "Epoch 16/20\n",
      "289/289 [==============================] - 10s 36ms/step - loss: 0.1360 - accuracy: 0.9454\n",
      "Epoch 17/20\n",
      "289/289 [==============================] - 10s 35ms/step - loss: 0.1176 - accuracy: 0.9564\n",
      "Epoch 18/20\n",
      "289/289 [==============================] - 10s 35ms/step - loss: 0.1488 - accuracy: 0.9430\n",
      "Epoch 19/20\n",
      "289/289 [==============================] - 11s 39ms/step - loss: 0.1212 - accuracy: 0.9541\n",
      "Epoch 20/20\n",
      "289/289 [==============================] - 10s 36ms/step - loss: 0.1146 - accuracy: 0.9570\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction from testing dataset\n",
    "\n",
    "y_pred = model.predict(X_test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 972,   47],\n",
       "       [ 172, 1114]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion amtrix from testing dataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
